{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('qvalues.json', \"r\") as f:\n",
    "            qvalues = json.load(f)\n",
    "qvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"('0', '2', '00')\",\n",
       " \"('0', '2', '0600')\",\n",
       " \"('0', '2', '6000')\",\n",
       " \"('0', '2', '600600')\",\n",
       " \"('0', '3', '00')\",\n",
       " \"('0', '3', '0600')\",\n",
       " \"('0', '3', '6000')\",\n",
       " \"('0', '3', '600600')\",\n",
       " \"('0', 'NA', '00')\",\n",
       " \"('0', 'NA', '0600')\",\n",
       " \"('0', 'NA', '6000')\",\n",
       " \"('0', 'NA', '600600')\",\n",
       " \"('1', '2', '00')\",\n",
       " \"('1', '2', '0600')\",\n",
       " \"('1', '2', '6000')\",\n",
       " \"('1', '2', '600600')\",\n",
       " \"('1', '3', '00')\",\n",
       " \"('1', '3', '0600')\",\n",
       " \"('1', '3', '6000')\",\n",
       " \"('1', '3', '600600')\",\n",
       " \"('1', 'NA', '00')\",\n",
       " \"('1', 'NA', '0600')\",\n",
       " \"('1', 'NA', '6000')\",\n",
       " \"('1', 'NA', '600600')\",\n",
       " \"('NA', '2', '00')\",\n",
       " \"('NA', '2', '0600')\",\n",
       " \"('NA', '2', '6000')\",\n",
       " \"('NA', '2', '600600')\",\n",
       " \"('NA', '3', '00')\",\n",
       " \"('NA', '3', '0600')\",\n",
       " \"('NA', '3', '6000')\",\n",
       " \"('NA', '3', '600600')\",\n",
       " \"('NA', 'NA', '00')\",\n",
       " \"('NA', 'NA', '0600')\",\n",
       " \"('NA', 'NA', '6000')\",\n",
       " \"('NA', 'NA', '600600')\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(qvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qvalues[\"('0', '2', '00')\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "import dataclasses\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class GameState:\n",
    "    snake: tuple\n",
    "    food: tuple\n",
    "\n",
    "\n",
    "class Learner(object):\n",
    "    def __init__(self, display_width, display_height, block_size):\n",
    "        # Game parameters\n",
    "        self.display_width = display_width\n",
    "        self.display_height = display_height\n",
    "        self.block_size = block_size\n",
    "\n",
    "        # Learning parameters\n",
    "        self.epsilon = 0.1\n",
    "        self.lr = 0.7\n",
    "        self.discount = 0.9\n",
    "\n",
    "        # State/Action history\n",
    "        self.qvalues = self.LoadQvalues()\n",
    "        self.history = []\n",
    "\n",
    "        # Action space\n",
    "        self.actions = {\n",
    "            0:'left',\n",
    "            1:'right',\n",
    "            2:'up',\n",
    "            3:'down'\n",
    "        }\n",
    "\n",
    "    def Reset(self):\n",
    "        self.history = []\n",
    "\n",
    "    def LoadQvalues(self, path=\"qvalues.json\"):\n",
    "        with open(path, \"r\") as f:\n",
    "            qvalues = json.load(f)\n",
    "        return qvalues\n",
    "\n",
    "    def SaveQvalues(self, path=\"qvalues.json\"):\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(self.qvalues, f)\n",
    "            \n",
    "    def act(self, snake, food):\n",
    "        state = self._GetState(snake, food)\n",
    "\n",
    "        # Epsilon greedy\n",
    "        rand = random.uniform(0,1)\n",
    "        if rand < self.epsilon:\n",
    "            action_key = random.choices(list(self.actions.keys()))[0]\n",
    "        else:\n",
    "            if self._GetStateStr(state) not in list(self.qvalues):\n",
    "                self.qvalues[self._GetStateStr(state)] = [0,0,0,0]\n",
    "                \n",
    "            state_scores = self.qvalues[self._GetStateStr(state)]\n",
    "            action_key = state_scores.index(max(state_scores))\n",
    "        action_val = self.actions[action_key]\n",
    "        \n",
    "        # Remember the actions it took at each state\n",
    "        self.history.append({\n",
    "            'state': state,\n",
    "            'action': action_key\n",
    "            })\n",
    "        return action_val\n",
    "    \n",
    "    def UpdateQValues(self, reason):\n",
    "        history = self.history[::-1]\n",
    "        for i, h in enumerate(history[:-1]):\n",
    "            if reason: # Snake Died -> Negative reward\n",
    "                sN = history[0]['state']\n",
    "                aN = history[0]['action']\n",
    "                state_str = self._GetStateStr(sN)\n",
    "                reward = -1\n",
    "                self.qvalues[state_str][aN] = (1-self.lr) * self.qvalues[state_str][aN] + self.lr * reward # Bellman equation - there is no future state since game is over\n",
    "                reason = None\n",
    "            else:\n",
    "                s1 = h['state'] # current state\n",
    "                s0 = history[i+1]['state'] # previous state\n",
    "                a0 = history[i+1]['action'] # action taken at previous state\n",
    "                \n",
    "                #x1 = s0.distance[0] # x distance at current state\n",
    "                #y1 = s0.distance[1] # y distance at current state\n",
    "    \n",
    "                #x2 = s1.distance[0] # x distance at previous state\n",
    "                #y2 = s1.distance[1] # y distance at previous state\n",
    "                \n",
    "                if s0.food != s1.food: # Snake ate a food, positive reward\n",
    "                    reward = 1\n",
    "                #elif (abs(x1) > abs(x2) or abs(y1) > abs(y2)): # Snake is closer to the food, positive reward\n",
    "                #    reward = 1\n",
    "                #else:\n",
    "                #    reward = -1 # Snake is further from the food, negative reward\n",
    "                else:\n",
    "                    reward = 0.1\n",
    "                    \n",
    "                state_str = self._GetStateStr(s0)\n",
    "                new_state_str = self._GetStateStr(s1)\n",
    "                self.qvalues[state_str][a0] = (1-self.lr) * (self.qvalues[state_str][a0]) + self.lr * (reward + self.discount*max(self.qvalues[new_state_str])) # Bellman equation\n",
    "\n",
    "\n",
    "    def _GetState(self, snake, food):\n",
    "        return GameState(snake, food)\n",
    "\n",
    "    def _GetStateStr(self, state):\n",
    "        return str((state.snake, state.food))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'([(290.0, 210.0)], (370.0, 50.0))'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0f2887d4d69a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGameLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Games: {game_count}; Score: {score}; Reason: {reason}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Output results of each game to console to monitor as agent is training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[0mgame_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-0f2887d4d69a>\u001b[0m in \u001b[0;36mGameLoop\u001b[1;34m()\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;31m# Update Q Table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUpdateQValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;31m# Next Frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-837e9e6b6c80>\u001b[0m in \u001b[0;36mUpdateQValues\u001b[1;34m(self, reason)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mstate_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_GetStateStr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[0mnew_state_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_GetStateStr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate_str\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate_str\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mreward\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscount\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_state_str\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Bellman equation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '([(290.0, 210.0)], (370.0, 50.0))'"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "import pygame\n",
    "import random\n",
    "\n",
    "pygame.init()\n",
    "\n",
    "#%% CONSTANTS\n",
    "YELLOW = (255, 255, 102)\n",
    "BLACK = (0, 0, 0)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (50, 153, 213)\n",
    "\n",
    "BLOCK_SIZE = 10 \n",
    "DIS_WIDTH = 600\n",
    "DIS_HEIGHT = 400\n",
    "\n",
    "QVALUES_N = 100\n",
    "FRAMESPEED = 500000\n",
    "\n",
    "#%% Game \n",
    "\n",
    "def GameLoop():\n",
    "    global dis\n",
    "    \n",
    "    dis = pygame.display.set_mode((DIS_WIDTH, DIS_HEIGHT))\n",
    "    pygame.display.set_caption('Snake')\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    # Starting position of snake\n",
    "    x1 = DIS_WIDTH / 2\n",
    "    y1 = DIS_HEIGHT / 2\n",
    "    x1_change = 0\n",
    "    y1_change = 0\n",
    "    snake_list = [(x1,y1)]\n",
    "    length_of_snake = 1\n",
    "\n",
    "    # Create first food\n",
    "    foodx = round(random.randrange(0, DIS_WIDTH - BLOCK_SIZE) / 10.0) * 10.0\n",
    "    foody = round(random.randrange(0, DIS_HEIGHT - BLOCK_SIZE) / 10.0) * 10.0\n",
    "\n",
    "    dead = False\n",
    "    reason = None\n",
    "    while not dead:\n",
    "        # Get action from agent\n",
    "        action = learner.act(snake_list, (foodx,foody))\n",
    "        if action == \"left\":\n",
    "            x1_change = -BLOCK_SIZE\n",
    "            y1_change = 0\n",
    "        elif action == \"right\":\n",
    "            x1_change = BLOCK_SIZE\n",
    "            y1_change = 0\n",
    "        elif action == \"up\":\n",
    "            y1_change = -BLOCK_SIZE\n",
    "            x1_change = 0\n",
    "        elif action == \"down\":\n",
    "            y1_change = BLOCK_SIZE\n",
    "            x1_change = 0\n",
    "\n",
    "        # Move snake\n",
    "        x1 += x1_change\n",
    "        y1 += y1_change\n",
    "        snake_head = (x1,y1)\n",
    "        snake_list.append(snake_head)\n",
    "\n",
    "        # Check if snake is off screen\n",
    "        if x1 >= DIS_WIDTH or x1 < 0 or y1 >= DIS_HEIGHT or y1 < 0:\n",
    "            reason = 'Screen'\n",
    "            dead = True\n",
    "\n",
    "        # Check if snake hit tail\n",
    "        if snake_head in snake_list[:-1]:\n",
    "            reason = 'Tail'\n",
    "            dead = True\n",
    "\n",
    "        # Check if snake ate food\n",
    "        if x1 == foodx and y1 == foody:\n",
    "            foodx = round(random.randrange(0, DIS_WIDTH - BLOCK_SIZE) / 10.0) * 10.0\n",
    "            foody = round(random.randrange(0, DIS_HEIGHT - BLOCK_SIZE) / 10.0) * 10.0\n",
    "            length_of_snake += 1\n",
    "\n",
    "        # Delete the last cell since we just added a head for moving, unless we ate a food\n",
    "        if len(snake_list) > length_of_snake:\n",
    "            del snake_list[0]\n",
    "\n",
    "        # Draw food, snake and update score\n",
    "        dis.fill(BLUE)\n",
    "        DrawFood(foodx, foody)\n",
    "        DrawSnake(snake_list)\n",
    "        DrawScore(length_of_snake - 1)\n",
    "        pygame.display.update()\n",
    "\n",
    "        # Update Q Table\n",
    "        learner.UpdateQValues(reason)\n",
    "        \n",
    "        # Next Frame\n",
    "        clock.tick(FRAMESPEED)\n",
    "\n",
    "    return length_of_snake - 1, reason\n",
    "\n",
    "def DrawFood(foodx, foody):\n",
    "    pygame.draw.rect(dis, GREEN, [foodx, foody, BLOCK_SIZE, BLOCK_SIZE])   \n",
    "\n",
    "def DrawScore(score):\n",
    "    font = pygame.font.SysFont(\"comicsansms\", 35)\n",
    "    value = font.render(f\"Score: {score}\", True, YELLOW)\n",
    "    dis.blit(value, [0, 0])\n",
    "\n",
    "def DrawSnake(snake_list):\n",
    "    for x in snake_list:\n",
    "        pygame.draw.rect(dis, BLACK, [x[0], x[1], BLOCK_SIZE, BLOCK_SIZE])\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "game_count = 1\n",
    "\n",
    "learner = Learner(DIS_WIDTH, DIS_HEIGHT, BLOCK_SIZE)\n",
    "\n",
    "while True:\n",
    "    learner.Reset()\n",
    "    if game_count > 100:\n",
    "        learner.epsilon = 0\n",
    "    else:\n",
    "        learner.epsilon = .1\n",
    "    score, reason = GameLoop()\n",
    "    print(f\"Games: {game_count}; Score: {score}; Reason: {reason}\") # Output results of each game to console to monitor as agent is training\n",
    "    game_count += 1\n",
    "    if game_count % QVALUES_N == 0: # Save qvalues every qvalue_dump_n games\n",
    "        print(\"Save Qvals\")\n",
    "        learner.SaveQvalues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
